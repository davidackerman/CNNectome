{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNNectome.validation.organelles.segmentation_metrics import Evaluator,EvaluationMetrics,display_name\n",
    "import h5py\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import zarr\n",
    "import imageio\n",
    "import tifffile\n",
    "import seaborn\n",
    "import math\n",
    "import pandas\n",
    "from scipy.ndimage import gaussian_filter, label, distance_transform_edt\n",
    "from CNNectome.utils.compute_label_distribution import distance\n",
    "\n",
    "\n",
    "class Cropper:\n",
    "    def __init__(self, mins, maxs):\n",
    "        self.mins = tuple(mins)\n",
    "        self.maxs = tuple(maxs)\n",
    "    \n",
    "    def crop(self, im, rescale_factor = 1):\n",
    "        if rescale_factor != 1:\n",
    "            im = im.repeat(rescale_factor, axis=0).repeat(rescale_factor, axis=1).repeat(rescale_factor, axis=2)\n",
    "        im = im[self.mins[0]:self.maxs[0],self.mins[1]:self.maxs[1],self.mins[2]:self.maxs[2]]\n",
    "        return im\n",
    "\n",
    "class Row:\n",
    "    def __init__(self, row):\n",
    "        self.row = row\n",
    "\n",
    "    def get(self, column, subcolumn=None):\n",
    "        c = self.row[column]\n",
    "        if \"x\" in c:\n",
    "            return [int(c[\"z\"]), int(c[\"y\"]), int(c[\"x\"])]\n",
    "        elif \"x min\" in c:\n",
    "            return [int(c[\"z min\"]), int(c[\"y min\"]), int(c[\"x min\"])], [int(c[\"z max\"]), int(c[\"y max\"]), int(c[\"x max\"])]\n",
    "        else:\n",
    "            # Way to treat it when  contains eg unnamed 0_level_0\n",
    "            return c[c.keys()[0]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories=[\"/groups/cosem/cosem/annotations/training/\",\n",
    "\"/groups/cosem/cosem/annotation_and_analytics/training/rymert/\",\n",
    "\"/groups/cosem/cosem/annotation_and_analytics/training/forknalln/\",\n",
    "\"/groups/cosem/cosem/annotation_and_analytics/training/ludwigh/\"]\n",
    "\n",
    "for group in [1]:\n",
    "    for crop in ['01','02','03','04','05','06','07','08','09','10']:\n",
    "        output_dir = f\"/groups/cosem/cosem/ackermand/annotation_and_analytics/group{group}-labels/group{group}_{crop}/\"\n",
    "        os.system(f\"mkdir -p {output_dir}\")\n",
    "        for directory in directories:\n",
    "            if directory==\"/groups/cosem/cosem/annotations/training/\":\n",
    "                group_crop_dir = f\"{directory}/group{group}-labels/group{group}_{crop}/\"\n",
    "            else:\n",
    "                group_crop_dir = f\"{directory}/group{group}-labels/\"\n",
    "\n",
    "            annotator_dirs = [os.path.join(group_crop_dir,dI) for dI in os.listdir(group_crop_dir) if os.path.isdir(os.path.join(group_crop_dir,dI))]\n",
    "            for annotator_dir in annotator_dirs:\n",
    "                if f\"group{group}_{crop}\" in annotator_dir:\n",
    "                    #print(f\"ln -s {annotator_dir} {output_dir}\")\n",
    "                    os.system(f\"ln -s {annotator_dir} {output_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new groups/crops\n",
    "# want actual predictions and segmentations as well...\n",
    "# w,x,y,z\n",
    "results_dict = {\n",
    "    'macrophage':{\n",
    "        'offset': np.array([0,0,0]),\n",
    "        'resolution': 4,\n",
    "        'rescale_factor_for_annotation': 2,\n",
    "        'result_types':{\n",
    "            'predictions':{\n",
    "                'mito': {'path':'/nrs/cosem/cosem/training/v0003.2/setup03/Macrophage_FS80_Cell2_4x4x4nm/Cryo_FS80_Cell2_4x4x4nm_it1100000.n5','name':'mito'},\n",
    "                'mito_membrane': {'path':'/nrs/cosem/cosem/training/v0003.2/setup03/Macrophage_FS80_Cell2_4x4x4nm/Cryo_FS80_Cell2_4x4x4nm_it650000.n5', 'name': 'mito_membrane'}\n",
    "            },\n",
    "            'refinements':{\n",
    "                'mito': {'path': '/groups/cosem/cosem/ackermand/paperResultsWithFullPaths/collected/renumbered/Macrophage.n5', 'name': 'mito_cropped'},\n",
    "                'mito_membrane': {'path': '/groups/cosem/cosem/ackermand/paperResultsWithFullPaths/collected/renumbered/Macrophage.n5', 'name': 'mito_membrane'}\n",
    "            }\n",
    "        },\n",
    "        'crops':{\n",
    "            'group1_03': #macrophage \n",
    "                {\n",
    "                'x': np.array([3840, 3840+200]), #np.array([3875,3973]),#3840+np.array([71,266])//2, \n",
    "                'y': np.array([245,245+200]), #np.array([331,414]),# 245+np.array([172,339])//2, \n",
    "                'z': np.array([7426, 7426+200]) #np.array([7426,7506]),# # 7426+np.array([1,160])//2\n",
    "                }\n",
    "        }\n",
    "    },\n",
    "    'jrc_mus-liver':{\n",
    "        'offset': np.array([30984,30912,15728]),\n",
    "        'resolution': 4,\n",
    "        'rescale_factor_for_annotation': 1,\n",
    "        'result_types':{\n",
    "            'predictions':{\n",
    "                'mito':{'path':'/nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/liver_latest_setup04_many_masked_6-1_100000.n5', 'name':'mito'},\n",
    "                'mito_membrane': {'path':'/nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/liver_latest_setup04_many_masked_6-1_100000.n5','name':'mito_membrane'}\n",
    "            },\n",
    "            'refinements':{\n",
    "                'mito': {'path': '/groups/cosem/cosem/ackermand/cosem/jrc_mus-liver.n5/watershedAndAgglomeration/mito.n5', 'name': '25_0.975_smoothed_renumbered_filled_renumbered_cropped'},\n",
    "                'mito_membrane':{'path': '/groups/cosem/cosem/ackermand/cosem/withFullPaths/training/finetuning/jrc_mus-liver/liver_latest_setup04_many_masked_6-1_100000.n5', 'name':'mito_membrane_labeledWith_mito'}\n",
    "            },\n",
    "            'ariadne':{\n",
    "                'mito': {'path': '/groups/cosem/cosem/bennettd/ariadne/jrc_mus-liver.n5', 'name': 'mito_instance'},\n",
    "                #'mito_membrane':{'path': '/groups/cosem/cosem/bennettd/ariadne/jrc_mus-liver.n5', 'name':'cristae_instance'}\n",
    "\n",
    "            }\n",
    "        },\n",
    "        'crops':{\n",
    "            'group1_09': \n",
    "                {'x': np.array([11400,11400+400]),#\t14700\t8550 np.array([11430,11540]),# 5700*2+np.array([30,140]),\n",
    "                'y': np.array([14700,14700+400]),#np.array([14980,15050]),# 7350*2+np.array([280,350]), \n",
    "                'z': np.array([8550,8550+400]) #np.array([8690,8830]),#4275*2+np.array([140,280]),\n",
    "                }\n",
    "        }\n",
    "    },\n",
    "      'jrc_mus-liver2':{\n",
    "        'offset': np.array([0,0,0]),\n",
    "        'resolution': 4,\n",
    "        'rescale_factor_for_annotation': 1,\n",
    "        'result_types':{\n",
    "            'predictions':{\n",
    "                'mito':{'path':'/nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/group1_08_liver_latest_setup04_many_masked_6-1_100000.n5', 'name':'mito'},\n",
    "                'mito_membrane': {'path':'/nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/group1_08_liver_latest_setup04_many_masked_6-1_100000.n5','name':'mito_membrane'}\n",
    "            },\n",
    "        },\n",
    "        'crops':{\n",
    "            'group1_08': \n",
    "                 {'x': np.array([0,400]),\n",
    "                 'y': np.array([0,400]),\n",
    "                 'z': np.array([0,400]),\n",
    "                 },\n",
    "            'group1_10': \n",
    "                 {'x': np.array([0,400]),\n",
    "                 'y': np.array([0,400]),\n",
    "                 'z': np.array([0,400]),\n",
    "                 }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "}\n",
    "labels_dict = {'mito': 4, 'mito_membrane': 3, 'mito_lumen': 4, 'mito_dna': 5}\n",
    "# we will label mito as 4 so that when we then label membrane, lumen+mito_membrane will be mito\n",
    "for cell in [\"jrc_mus-liver2\"]:\n",
    "    cell_results = results_dict[cell]\n",
    "    resolution = cell_results[\"resolution\"]\n",
    "    offset = cell_results[\"offset\"]//resolution\n",
    "    rescale_factor_for_annotation = cell_results[\"rescale_factor_for_annotation\"]\n",
    "\n",
    "    crop_count = 0\n",
    "    for crop_id,crop in cell_results['crops'].items():\n",
    "        crop_count += 1\n",
    "        x = crop[\"x\"]-offset[0] #[results[\"x\"][0],results[\"x\"][0]+(results[\"x\"][1]-results[\"x\"][0])//2]\n",
    "        y = crop[\"y\"]-offset[1] #[results[\"y\"][0],results[\"y\"][0]+(results[\"y\"][1]-results[\"y\"][0])//2]\n",
    "        z = crop[\"z\"]-offset[2] #[results[\"z\"][0],results[\"z\"][0]+(results[\"z\"][1]-results[\"z\"][0])//2]\n",
    "\n",
    "        # labels mito_mem (3)\tmito_lumen (4)\tmito_dna (5)\n",
    "        for result_type_name, result_type_properties in cell_results[\"result_types\"].items():\n",
    "            combined_image = np.zeros((x[1]-x[0],y[1]-y[0],z[1]-z[0]),dtype=np.uint8)\n",
    "            for current_organelle_name,current_organelle_properties in result_type_properties.items():\n",
    "                current_organelle_result_path = current_organelle_properties['path']\n",
    "                current_organelle_result_name = current_organelle_properties['name']\n",
    "                if result_type_name == \"ariadne\":\n",
    "                    x_rescaled = x//2\n",
    "                    y_rescaled = y//2\n",
    "                    z_rescaled = z//2\n",
    "                    combined_image = np.zeros((x_rescaled[1]-x_rescaled[0],y_rescaled[1]-y_rescaled[0],z_rescaled[1]-z_rescaled[0]),dtype=np.uint8)\n",
    "\n",
    "                    current_organelle_results_zarr = zarr.open(current_organelle_result_path, mode=\"r\")[\"multiscale\"][\"labels\"][current_organelle_result_name][\"s0\"]\n",
    "                    current_organelle_results = current_organelle_results_zarr[z_rescaled[0]:z_rescaled[1],y_rescaled[0]:y_rescaled[1],x_rescaled[0]:x_rescaled[1]]                   \n",
    "                    combined_image[current_organelle_results>=1]=labels_dict[current_organelle_name] #label their mito as lumen\n",
    "                    #rescale_factor_for_annotation = 2 # since ariadne is at 8 nm but annotations are at 4\n",
    "                elif result_type_name == \"predictions\":\n",
    "                    if cell == \"jrc_mus-liver\":\n",
    "                        current_organelle_results_zarr = zarr.open(current_organelle_result_path, mode=\"r\")[\"volumes\"][current_organelle_result_name][\"s0\"]\n",
    "                    elif cell == \"jrc_mus-liver2\":\n",
    "                        current_organelle_results_zarr = zarr.open(current_organelle_result_path, mode=\"r\")[\"volumes\"][current_organelle_result_name]\n",
    "                    else:\n",
    "                        current_organelle_results_zarr = zarr.open(current_organelle_result_path, mode=\"r\")[current_organelle_result_name]\n",
    "                    current_organelle_results = current_organelle_results_zarr[z[0]:z[1],y[0]:y[1],x[0]:x[1]]\n",
    "                    combined_image[current_organelle_results>=127]=labels_dict[current_organelle_name]\n",
    "                else:\n",
    "                    current_organelle_results_zarr = zarr.open(current_organelle_result_path, mode=\"r\")[current_organelle_result_name]\n",
    "                    current_organelle_results = current_organelle_results_zarr[z[0]:z[1],y[0]:y[1],x[0]:x[1]]\n",
    "                    combined_image[current_organelle_results>=1]=labels_dict[current_organelle_name]\n",
    "\n",
    "            combined_image = combined_image.repeat(rescale_factor_for_annotation, axis=0).repeat(rescale_factor_for_annotation, axis=1).repeat(rescale_factor_for_annotation, axis=2)\n",
    "            os.system(f\"rm /groups/cosem/cosem/ackermand/annotation_and_analytics/group1-labels/{crop_id}/{crop_id}_{crop_count}{result_type_name}.tif\")\n",
    "            os.system(f\"mkdir /groups/cosem/cosem/ackermand/annotation_and_analytics/group1-labels/{crop_id}/{crop_id}_{crop_count}{result_type_name}\")\n",
    "            tifffile.imsave(f\"/groups/cosem/cosem/ackermand/annotation_and_analytics/group1-labels/{crop_id}/{crop_id}_{crop_count}{result_type_name}/{crop_id}_{crop_count}{result_type_name}.tif\",combined_image)\n",
    "\n",
    "\n",
    "\n",
    "# macrophage mito (original): 25\n",
    "# 500\n",
    "# #/nrs/cosem/cosem/training/v0003.2/setup25/Macrophage_FS80_Cell2_4x4x4nm/Cryo_FS80_Cell2_4x4x4nm_it500000.n5/mito\n",
    "\n",
    "# wanted more coverage for macro mito (https://scicomp-software.slack.com/archives/DLQBV2T61/p1592227786087400)\n",
    "# 3\n",
    "# 1100\n",
    "# /nrs/cosem/cosem/training/v0003.2/setup03/Macrophage_FS80_Cell2_4x4x4nm/Cryo_FS80_Cell2_4x4x4nm_it1100000.n5/mito\n",
    "# /groups/cosem/cosem/ackermand/paperResultsWithFullPaths/collected/renumbered/Macrophage.n5/mito\n",
    "\n",
    "# macrophage mito mem: 3\n",
    "# 650\n",
    "# /nrs/cosem/cosem/training/v0003.2/setup03/Macrophage_FS80_Cell2_4x4x4nm/Cryo_FS80_Cell2_4x4x4nm_it650000.n5/mito_membrane\n",
    "# /groups/cosem/cosem/ackermand/paperResultsWithFullPaths/collected/renumbered/Macrophage.n5/mito_membrane\n",
    "\n",
    "# mus liver:\n",
    "# /nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/liver_latest_setup04_many_masked_6-1_100000.n5\n",
    "# membrane- training\\finetuning\\jrc_mus-liver\\liver_latest_setup04_many_masked_6-1_100000.n5\n",
    "# mito - /nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/liver_latest_setup04_many_masked_6-1_100000.n5\n",
    "# mito - dna /nrs/cosem/pattonw/training/finetuning/jrc_mus-liver/liver_best_setup26.1_mito-1_45000.n5\n",
    "\n",
    "\n",
    "# ariadne:\n",
    "# /groups/cosem/cosem/bennettd/ariadne/jrc_mus-liver.n5/multiscale/labels/mito\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 group1_01\n",
      "group1_01_2a\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d838db044ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m                             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_loc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mdf_loc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"MaskingInformationAmiraCoordinates.csv\", newline='') as csvfile:\n",
    "    column_names = [\"Organelle Name\", \"Trial\"] + [metric.value for metric in EvaluationMetrics]\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    df_loc=0\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for idx, row in enumerate(reader):\n",
    "        if idx==0:\n",
    "            all_organelle_names = [s.split(\" (\")[0] for s in row[20:]]\n",
    "            all_organelle_labels = [int(s[s.find(\"(\")+1:s.find(\")\")]) for s in row[20:]]\n",
    "\n",
    "        if idx>=2 and idx<12: #idx > 1 and idx < 62:\n",
    "            group_id = row[0]\n",
    "            print(idx,group_id)\n",
    "            dataset_path = row[3].replace(\"\\\\\",\"/\").replace(\"Z:\",\"/groups/cosem/cosem\")\n",
    "            row[4:16] = [int(row[i]) for i in range(4, 16)]\n",
    "            dims = (row[6], row[5], row[4])\n",
    "            gt_resolution = [row[7],row[8], row[9]]\n",
    "            resolution = [gt_resolution[0]/2, gt_resolution[1]/2, gt_resolution[2]/2]\n",
    "            mins = (row[14], row[12], row[10])\n",
    "            maxs = (row[15], row[13], row[11])\n",
    "            cropper = Cropper(mins,maxs)\n",
    "\n",
    "            organelle_labels = [all_organelle_labels[i] for i,c in enumerate(row[20:]) if c==\"X\"]\n",
    "\n",
    "            if 3 in organelle_labels or 4 in organelle_labels or 5 in organelle_labels:\n",
    "                organelle_labels.append(0) # This will be used to identify when we need to lable entire mitos\n",
    "\n",
    "            # get ground truth\n",
    "            with h5py.File(dataset_path, \"r\") as f:\n",
    "                #HACK\n",
    "                if \"group1_08\" in group_id or \"group1_10\" in group_id:\n",
    "                    gt = cropper.crop(f['volumes']['labels']['gt'][:],rescale_factor = 2) \n",
    "                else:\n",
    "                    gt = cropper.crop(f['volumes']['labels']['gt'][:])\n",
    "            #plt.imshow(gt[:,:,10],vmin=0,vmax=10)\n",
    "            #plt.show()\n",
    "            # get test data\n",
    "            #test_base_path = f'/groups/cosem/cosem/annotations/training/{group_id.split(\"_\")[0]}-labels/{group_id}'\n",
    "            test_base_path = f'/groups/cosem/cosem/ackermand/annotation_and_analytics/{group_id.split(\"_\")[0]}-labels/{group_id}'\n",
    "            for test_directory in os.listdir(test_base_path):\n",
    "                print(test_directory)\n",
    "                test_image_path = f'{test_base_path}/{test_directory}/{test_directory}.tif'\n",
    "                test_txt_path = f'{test_base_path}/{test_directory}/{test_directory}.txt'\n",
    "\n",
    "                # file = open(test_txt_path, \"r\")\n",
    "                # for line in file:\n",
    "                #     if re.search(\"Voxel size:\", line):\n",
    "                #         print(line)\n",
    "                #         print(line.split(\"Voxel size:\"))\n",
    "                # file = open(\"grep_sample.txt\", \"r\")\n",
    "                #HACK\n",
    "                try:\n",
    "                    test_image = cropper.crop(tifffile.imread(test_image_path))\n",
    "                except FileNotFoundError:\n",
    "                    test_image_path=test_image_path[:-6] + '.tif'\n",
    "                    test_image = cropper.crop(tifffile.imread(test_image_path))\n",
    "\n",
    "                #plt.imshow(test_image[:,:,10],vmin=0,vmax=10)\n",
    "                #plt.show()\n",
    "                for i,organelle_label in enumerate(organelle_labels):\n",
    "                    organelle_name = all_organelle_names[i]\n",
    "                    if organelle_label==0:\n",
    "                        organelle_name = \"mito\"\n",
    "                        gt_binary = ( (gt>=3) & (gt<=5))\n",
    "                        test_image_binary = ( (test_image>=3) & (test_image<=5))\n",
    "                    else:\n",
    "                        gt_binary = gt==organelle_label\n",
    "                        test_image_binary = test_image==organelle_label\n",
    "                    \n",
    "                    metric_params={'tol_distance':40,'clip_distance': 200,'threshold': 127}\n",
    "                    evaluator = Evaluator(gt_binary, test_image_binary, not gt_binary.any, not test_image_binary.any, metric_params, resolution=resolution)\n",
    "                    #f, axarr = plt.subplots(1,2) \n",
    "                    #axarr[0].imshow(gt_binary[:,:,10])\n",
    "                    #axarr[1].imshow(test_image_binary[:,:,10])\n",
    "                    row = [organelle_name, test_directory]\n",
    "                    for metric in EvaluationMetrics:\n",
    "                        if display_name(metric)==\"Recall\":\n",
    "                            try:\n",
    "                                #TODO: This shouldn't be necessary, just temporary fix\n",
    "                                score = evaluator.compute_score(metric)\n",
    "                            except:\n",
    "                                score = float(\"NaN\")\n",
    "                        row.append(score)\n",
    "                    df.loc[df_loc] = row\n",
    "                    df_loc+=1\n",
    "                # print(id, evaluator.dice(), evaluator.f1_score(), evaluator.false_negative_rate(), evaluator.false_positive_rate())\n",
    "        #segmentation_metrics.Evaluator(gt_binary, test_binary, truth_empty,test_empty)\n",
    "df = df.sort_values(by=['Organelle Name', 'Trial'], ascending=[True, True])\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score(scores_dict, title, do_avg = False):\n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    if do_avg:\n",
    "        width = 0.5\n",
    "    else:\n",
    "        max_count = 0\n",
    "        for annotator in scores_dict.keys():\n",
    "            for organelle in scores_dict[annotator].keys():\n",
    "                if len(scores_dict[annotator][organelle])>max_count:\n",
    "                    max_count = len(scores_dict[annotator][organelle])\n",
    "        width = 1/(len(scores_dict)*max_count)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,2,1])\n",
    "    annotator_gap = 0\n",
    "    annotator_gap_width = 1/len(scores_dict)\n",
    "    organelle_gap_width = 1.5\n",
    "    for annotator in scores_dict.keys():\n",
    "        organelle_gap = 0\n",
    "        X = []\n",
    "        Y = []\n",
    "        YERR = []\n",
    "        labels = []\n",
    "        for organelle,scores in scores_dict[annotator].items():\n",
    "            if do_avg:\n",
    "                X.append(annotator_gap+organelle_gap+width/2)\n",
    "                Y.append(scores[0])\n",
    "                YERR.append(scores[1])\n",
    "            else:\n",
    "                X.extend(width*np.arange(len(scores))+annotator_gap+organelle_gap+width/2)\n",
    "                Y.extend(scores)\n",
    "            organelle_gap+=organelle_gap_width\n",
    "            labels.append(organelle)\n",
    "        if do_avg:\n",
    "            ax.bar(X, Y, yerr=YERR, width = width, edgecolor = \"black\",label=f\"Annotator {annotator}\",capsize=10)\n",
    "        else:\n",
    "            ax.bar(X, Y, width = width, edgecolor = \"black\",label=f\"Annotator {annotator}\")\n",
    "        annotator_gap+=annotator_gap_width\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Organelles\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_xticks(np.arange(len(labels))*organelle_gap_width+0.5)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "score_name = \"dice\"\n",
    "trials = df['Trial'].tolist()\n",
    "organelles = df['Organelle Name'].tolist()\n",
    "scores = df[score_name].tolist()\n",
    "scores_dict = {}\n",
    "\n",
    "for idx,current_trial in enumerate(trials):\n",
    "    annotator = current_trial.split(\"_\")[-1]\n",
    "    if annotator not in scores_dict:\n",
    "        scores_dict[annotator] = {}\n",
    "\n",
    "    organelle = organelles[idx]\n",
    "    if organelle not in scores_dict[annotator]:\n",
    "        scores_dict[annotator][organelle] = [scores[idx]]\n",
    "    else:\n",
    "        scores_dict[annotator][organelle].append(scores[idx])\n",
    "\n",
    "plot_score(scores_dict, score_name)\n",
    "\n",
    "# update to do averages\n",
    "for annotator in scores_dict.keys():\n",
    "    for organelle in scores_dict[annotator].keys():\n",
    "        mean = np.nanmean(scores_dict[annotator][organelle])\n",
    "        std = np.nanstd(scores_dict[annotator][organelle])\n",
    "        scores_dict[annotator][organelle] = [mean, std]\n",
    "\n",
    "plot_score(scores_dict, score_name, do_avg=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "score_names = df.columns.tolist()[2:]\n",
    "for score_name in score_names:\n",
    "    trials = df['Trial'].tolist()\n",
    "    organelles = df['Organelle Name'].tolist()\n",
    "    scores = df[score_name].tolist()\n",
    "    scores_dict = {}\n",
    "\n",
    "    for idx,current_trial in enumerate(trials):\n",
    "        crop = current_trial.split(\"_\")[1]\n",
    "        annotator = current_trial.split(\"_\")[2][1:]\n",
    "\n",
    "        #rename to keep it in nice order\n",
    "        if annotator == \"predictions\":\n",
    "            annotator = \"xpredictions\"\n",
    "        elif annotator == \"refinements\":\n",
    "            annotator = \"yrefinements\"\n",
    "        elif annotator == \"ariadne\":\n",
    "            annotator = \"zariadne\"\n",
    "\n",
    "        organelle = organelles[idx]\n",
    "        if organelle not in scores_dict:\n",
    "            scores_dict[organelle] = {}\n",
    "        if crop not in scores_dict[organelle]:\n",
    "            scores_dict[organelle][crop] = {annotator:[scores[idx]]}\n",
    "        else:\n",
    "            if annotator not in scores_dict[organelle][crop]:\n",
    "                scores_dict[organelle][crop][annotator] = [scores[idx]]\n",
    "            else:\n",
    "                scores_dict[organelle][crop][annotator].append(scores[idx])\n",
    "\n",
    "    for organelle in scores_dict.keys():\n",
    "        for crop in scores_dict[organelle].keys():\n",
    "            scores_dict[organelle][crop] = collections.OrderedDict(sorted(scores_dict[organelle][crop].items()))\n",
    "        scores_dict[organelle] = collections.OrderedDict(sorted(scores_dict[organelle].items()))\n",
    "\n",
    "    # plot\n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    all_annotators = set()\n",
    "    max_crops_per_organelle = 0\n",
    "    max_scores_per_crop_per_annotator = 0\n",
    "    max_scores_per_crop = 0\n",
    "    for organelle in scores_dict.keys():\n",
    "        scores_per_organelle = 0\n",
    "        crops_per_organelle = 0\n",
    "        for crop in scores_dict[organelle].keys():\n",
    "            crops_per_organelle+=1\n",
    "            scores_per_crop = 0\n",
    "            for annotator,scores in scores_dict[organelle][crop].items():\n",
    "                all_annotators.add(annotator)\n",
    "                scores_per_crop_per_annotator=len(scores)\n",
    "                scores_per_crop += scores_per_crop_per_annotator\n",
    "                if scores_per_crop_per_annotator>max_scores_per_crop_per_annotator:\n",
    "                    max_scores_per_crop_per_annotator = scores_per_crop_per_annotator\n",
    "            if scores_per_crop>max_scores_per_crop:\n",
    "                max_scores_per_crop = scores_per_crop\n",
    "\n",
    "        if crops_per_organelle>max_crops_per_organelle:\n",
    "            max_crops_per_organelle = crops_per_organelle\n",
    "\n",
    "    num_annotators = len(all_annotators)\n",
    "    organelle_width = 1.5\n",
    "    organelle_gap = 0.1\n",
    "    crop_gap = 0.025\n",
    "    crop_width = (organelle_width-(max_crops_per_organelle-1)*crop_gap)/max_crops_per_organelle\n",
    "    width = crop_width/max_scores_per_crop #(num_annotators*max_scores_per_crop_per_annotator)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,3,1])\n",
    "    X = {}\n",
    "    Y = {}\n",
    "    labels = []\n",
    "    labels_x = []\n",
    "    organelle_start = 0\n",
    "    for organelle in scores_dict.keys():\n",
    "        labels_x.append(organelle_start+0.5*organelle_width)\n",
    "        labels.append(f\"\\n\\n{organelle}\")\n",
    "        for crop_idx,crop in enumerate(scores_dict[organelle].keys()):\n",
    "            num_crops = len(scores_dict[organelle])\n",
    "            crop_start = (crop_width+crop_gap)*crop_idx+organelle_start\n",
    "            centered_crop_start = crop_start + organelle_width/2 - (crop_width*num_crops+crop_gap*(num_crops-1))/2\n",
    "            labels_x.append(centered_crop_start+0.5*crop_width)\n",
    "            labels.append(crop)\n",
    "\n",
    "            num_scores_for_crop = 0\n",
    "            for annotator in scores_dict[organelle][crop].keys():\n",
    "                num_scores_for_crop += len(scores_dict[organelle][crop][annotator])\n",
    "            annotator_start = centered_crop_start + crop_width/2 - num_scores_for_crop*width/2\n",
    "            for annotator_idx,annotator in enumerate(scores_dict[organelle][crop].keys()):\n",
    "                if annotator not in X:\n",
    "                    X[annotator] = []\n",
    "                    Y[annotator] = []\n",
    "                scores = scores_dict[organelle][crop][annotator]\n",
    "                X[annotator].extend(annotator_start+width*np.arange(len(scores)))\n",
    "                annotator_start+=width*len(scores)\n",
    "                Y[annotator].extend(scores)\n",
    "        organelle_start+=organelle_width+organelle_gap\n",
    "    for annotator in X.keys():\n",
    "        if annotator == \"xpredictions\":\n",
    "            label = \"Predictions\"\n",
    "        elif annotator == \"yrefinements\":\n",
    "            label = \"Refinements\"\n",
    "        elif annotator == \"zariadne\":\n",
    "            label = \"Ariadne\"\n",
    "        else:\n",
    "            label = f\"Annotator {annotator}\"\n",
    "\n",
    "        ax.bar(X[annotator], Y[annotator], width = width, edgecolor = \"black\",label=label)\n",
    "\n",
    "    ax.legend(prop={'size':16})\n",
    "    ax.set_title(score_name, size=20)\n",
    "    ax.set_xlabel(\"Organelles\",size=18)\n",
    "    ax.set_ylabel(\"Score\",size=18)\n",
    "    ax.set_xticks(labels_x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    # hide tick lines for x axis\n",
    "    ax.tick_params(axis='x', which='both',length=0)\n",
    "    for label in ax.get_xmajorticklabels():\n",
    "        if '0' in label.get_text(): \n",
    "            label.set_rotation(45)\n",
    "        else:\n",
    "            label.set_fontsize(16)\n",
    "    plt.savefig(f'/groups/cosem/cosem/ackermand/annotation_and_analytics/plots/{score_name}.png',bbox_inches='tight')\n",
    "#ax.set_xlim(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group1_10\n"
     ]
    }
   ],
   "source": [
    "# all-to-all scores\n",
    "matplotlib.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "with open(\"MaskingInformationAmiraCoordinates.csv\", newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for idx, row in enumerate(reader):\n",
    "        if idx==0:\n",
    "            all_organelle_names = [s.split(\" (\")[0] for s in row[20:]]\n",
    "            all_organelle_labels = [int(s[s.find(\"(\")+1:s.find(\")\")]) for s in row[20:]]\n",
    "\n",
    "        if idx==11: #idx>=2 and idx<11: #idx > 1 and idx < 62:\n",
    "            group_id = row[0]\n",
    "            dataset_path = row[3].replace(\"\\\\\",\"/\").replace(\"Z:\",\"/groups/cosem/cosem\")\n",
    "            row[4:16] = [int(row[i]) for i in range(4, 16)]\n",
    "            dims = (row[6], row[5], row[4])\n",
    "            gt_resolution = [row[7],row[8], row[9]]\n",
    "            resolution = [gt_resolution[0]/2, gt_resolution[1]/2, gt_resolution[2]/2]\n",
    "            print(group_id)\n",
    "            mins = (row[14], row[12], row[10])\n",
    "            maxs = (row[15], row[13], row[11])\n",
    "            cropper = Cropper(mins,maxs)\n",
    "\n",
    "            organelle_labels = [all_organelle_labels[i] for i,c in enumerate(row[20:]) if c==\"X\"]\n",
    "\n",
    "            if 3 in organelle_labels or 4 in organelle_labels or 5 in organelle_labels:\n",
    "                organelle_labels.append(0) # This will be used to identify when we need to lable entire mitos\n",
    "\n",
    "            # get ground truth\n",
    "            with h5py.File(dataset_path, \"r\") as f:\n",
    "                #HACK\n",
    "                if \"group1_08\" in group_id or \"group1_10\" in group_id:\n",
    "                    original_gt_image = cropper.crop(f['volumes']['labels']['gt'][:],rescale_factor = 2) \n",
    "                else:\n",
    "                    original_gt_image = cropper.crop(f['volumes']['labels']['gt'][:])\n",
    "           \n",
    "            test_base_path = f'/groups/cosem/cosem/ackermand/annotation_and_analytics/{group_id.split(\"_\")[0]}-labels/{group_id}'\n",
    "            all_directories = os.listdir(test_base_path)\n",
    "            all_directories.append(\"use_original_gt\")\n",
    "            #all_directories = [i for i in all_directories if \"predictions\" not in i and \"refinements\" not in i and \"ariadne\" not in i]\n",
    "            all_to_all = {}\n",
    "            for i,organelle_label in enumerate(organelle_labels):\n",
    "                organelle_name = all_organelle_names[i]\n",
    "                if organelle_label==0:\n",
    "                    organelle_name = \"mito\"\n",
    "                all_to_all[organelle_name] = {}\n",
    "                for metric in EvaluationMetrics:\n",
    "                    all_to_all[organelle_name][display_name(metric)] = np.zeros((len(all_directories),len(all_directories)))\n",
    "\n",
    "            for gt_directory_idx,gt_directory in enumerate(all_directories):\n",
    "                if gt_directory == \"use_original_gt\":\n",
    "                    gt_image = original_gt_image\n",
    "                else:\n",
    "                    gt_image_path = f'{test_base_path}/{gt_directory}/{gt_directory}.tif'\n",
    "\n",
    "                    #HACK\n",
    "                    try:\n",
    "                        gt_image = cropper.crop(tifffile.imread(gt_image_path))\n",
    "                    except FileNotFoundError:\n",
    "                        gt_image_path=gt_image_path[:-6] + '.tif'\n",
    "                        gt_image = cropper.crop(tifffile.imread(gt_image_path))\n",
    "\n",
    "                for test_directory_idx in range(0, len(all_directories)):\n",
    "                    test_directory = all_directories[test_directory_idx]\n",
    "\n",
    "                    if test_directory == \"use_original_gt\":\n",
    "                        test_image = original_gt_image\n",
    "                    else:\n",
    "                        test_image_path = f'{test_base_path}/{test_directory}/{test_directory}.tif'\n",
    "\n",
    "                        #HACK\n",
    "                        try:\n",
    "                            test_image = cropper.crop(tifffile.imread(test_image_path))\n",
    "                        except FileNotFoundError:\n",
    "                            test_image_path=test_image_path[:-6] + '.tif'\n",
    "                            test_image = cropper.crop(tifffile.imread(test_image_path))\n",
    "\n",
    "                    for i,organelle_label in enumerate(organelle_labels):\n",
    "                        organelle_name = all_organelle_names[i]\n",
    "                        if organelle_label==0:\n",
    "                            organelle_name = \"mito\"\n",
    "                            gt_image_binary = ( (gt_image>=3) & (gt_image<=5))\n",
    "                            test_image_binary = ( (test_image>=3) & (test_image<=5))\n",
    "                        else:\n",
    "                            gt_image_binary = gt_image==organelle_label\n",
    "                            test_image_binary = test_image==organelle_label\n",
    "                        metric_params={'tol_distance':40,'clip_distance': 200,'threshold': 127}\n",
    "                        evaluator = Evaluator(gt_image_binary, test_image_binary, not gt_image_binary.any, not test_image_binary.any, metric_params, resolution=resolution)\n",
    "                        for metric in EvaluationMetrics:\n",
    "                            try:\n",
    "                                score = evaluator.compute_score(metric)\n",
    "                            except:\n",
    "                                score = float(\"NaN\")\n",
    "                            if score == np.nan_to_num(np.inf):\n",
    "                                score = float(\"NaN\") # Necessary for plotting\n",
    "                            all_to_all[organelle_name][display_name(metric)][gt_directory_idx][test_directory_idx] = score\n",
    "                        #print(i, gt_directory_idx, test_directory_idx, score, all_to_all[i][gt_directory_idx][test_directory_idx],all_to_all[0][0][1] )\n",
    "            \n",
    "            names_to_use = [directory.split(\"_\")[-1] for directory in all_directories]\n",
    "            for idx, name_to_use in enumerate(names_to_use):\n",
    "                if \"predictions\" in name_to_use:\n",
    "                    name_to_use = \"xxpredictions\"\n",
    "                elif \"refinements\" in name_to_use:\n",
    "                    name_to_use = \"yyrefinements\"\n",
    "                elif \"ariadne\" in name_to_use:\n",
    "                    name_to_use = \"zzariadne\"\n",
    "                elif \"gt\" in name_to_use:\n",
    "                    name_to_use = \"a0gt\"\n",
    "                else:\n",
    "                    name_to_use = name_to_use[-1]+name_to_use[-1]+name_to_use[::-1]\n",
    "                names_to_use[idx] = name_to_use\n",
    "            alphabetical_sort_order = [i[0] for i in sorted(enumerate(names_to_use), key=lambda x:x[1])]\n",
    "            names_to_use = [names_to_use[i][2:] for i in alphabetical_sort_order]\n",
    "            for i,organelle_label in enumerate(organelle_labels):\n",
    "                organelle_name = all_organelle_names[i]\n",
    "                if organelle_label==0:\n",
    "                    organelle_name = \"mito\"\n",
    "                for metric in EvaluationMetrics:\n",
    "                    fig, ax = plt.subplots(1,1,figsize=(8, 6), )\n",
    "                    current_all_to_all = all_to_all[organelle_name][display_name(metric)]\n",
    "                    current_all_to_all = current_all_to_all[alphabetical_sort_order,:]\n",
    "                    current_all_to_all = current_all_to_all[:,alphabetical_sort_order]\n",
    "                    seaborn.heatmap(current_all_to_all,annot=True)\n",
    "                    ax.set_title(organelle_name)\n",
    "                    ax.collections[0].colorbar.set_label(display_name(metric))\n",
    "                    ax.xaxis.tick_top()\n",
    "                    plt.xticks([i+0.5 for i in range(len(names_to_use))],names_to_use,rotation=45,ha='left')\n",
    "                    plt.yticks([i+0.5 for i in range(len(names_to_use))],names_to_use,rotation=0)\n",
    "                    output_directory = f'/groups/cosem/cosem/ackermand/annotation_and_analytics/plots/{group_id.split(\"_\")[0]}/{group_id}/{metric.value}'\n",
    "                    os.system(f\"mkdir -p {output_directory}\")\n",
    "                    os.system(f'rm {output_directory}/{organelle_name}.png')\n",
    "                    plt.savefig(f'{output_directory}/{organelle_name}.png',bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "        #segmentation_metrics.Evaluator(gt_binary, test_binary, truth_empty,test_empty)\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group1_08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/scicompsoft/home/ackermand/.local/lib/python3.6/site-packages/zarr/n5.py:419: RuntimeWarning: Not all N5 implementations support blosc compression (yet). You might not be able to open the dataset with another N5 library.\n",
      "  RuntimeWarning\n"
     ]
    }
   ],
   "source": [
    "# write out n5s\n",
    "\n",
    "df = pandas.read_csv(\"MaskingInformationAmiraCoordinatesNewColumns.csv\",header=[0,1])\n",
    "all_organelle_names = []\n",
    "all_organelle_labels = []\n",
    "for c in df.columns:\n",
    "    c = c[0]\n",
    "    if re.search(r'\\(\\d\\)',c) or re.search(r'\\(\\d\\d\\)', c):\n",
    "        all_organelle_names.append(c.split(\" (\")[0])\n",
    "        all_organelle_labels.append(int(c[c.find(\"(\")+1:c.find(\")\")]))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    organelle_labels = [int(h[0].split(\"(\")[1].split(\")\")[0]) for h,c in row.iteritems() if c==\"X\"]\n",
    "    row = Row(row)\n",
    "\n",
    "    if index==7:\n",
    "        all_images = []\n",
    "        group_id = row.get('group')\n",
    "        print(group_id)\n",
    "\n",
    "        raw_data_path = row.get('raw data').replace(\"\\\\\",\"/\").replace(\"Z:\",\"/groups/cosem/cosem\")\n",
    "        dataset_path = row.get('crop pathway').replace(\"\\\\\",\"/\").replace(\"Z:\",\"/groups/cosem/cosem\")\n",
    "        original_coordinates = row.get(\"original coordinates\")\n",
    "        gt_resolution = row.get(\"voxel size (nm)\")\n",
    "        mins, maxs = row.get(\"coordinates within crop\")\n",
    "        resolution = [gt_resolution[0]/2, gt_resolution[1]/2, gt_resolution[2]/2]\n",
    "        cropper = Cropper(mins,maxs)\n",
    "        \n",
    "        if 3 in organelle_labels or 4 in organelle_labels or 5 in organelle_labels:\n",
    "            organelle_labels.append(0) # This will be used to identify when we need to lable entire mitos\n",
    "        # get ground truth\n",
    "        with h5py.File(dataset_path, \"r\") as f:\n",
    "            #HACK\n",
    "            if \"group1_08\" in group_id or \"group1_10\" in group_id:\n",
    "                original_gt_image = cropper.crop(f['volumes']['labels']['gt'][:],rescale_factor = 2) \n",
    "            else:\n",
    "                original_gt_image = cropper.crop(f['volumes']['labels']['gt'][:])\n",
    "\n",
    "        test_base_path = f'/groups/cosem/cosem/ackermand/annotation_and_analytics/{group_id.split(\"_\")[0]}-labels/{group_id}'\n",
    "        all_directories = os.listdir(test_base_path)\n",
    "        all_directories.append(\"use_original_gt\")\n",
    "        #all_directories = [i for i in all_directories if \"predictions\" not in i and \"refinements\" not in i and \"ariadne\" not in i]\n",
    "        all_to_all = np.zeros((len(organelle_labels),len(all_directories),len(all_directories)))\n",
    "        n5_path = f'/groups/cosem/cosem/ackermand/annotation_and_analytics/n5s/{group_id.split(\"_\")[0]}/{group_id}.n5'\n",
    "\n",
    "        os.system(f\"rm -rf {n5_path}\")\n",
    "        os.system(f\"mkdir -p {n5_path}\")\n",
    "        store = zarr.N5Store(n5_path)\n",
    "        root = zarr.group(store=store, overwrite=True)\n",
    "\n",
    "        #raw data:\n",
    "\n",
    "\n",
    "        for i,current_directory in enumerate(all_directories):\n",
    "            if current_directory == \"use_original_gt\":\n",
    "                current_image = original_gt_image\n",
    "            else:\n",
    "                current_image_path = f'{test_base_path}/{current_directory}/{current_directory}.tif'\n",
    "\n",
    "                #HACK\n",
    "                try:\n",
    "                    current_image = cropper.crop(tifffile.imread(current_image_path))\n",
    "                except FileNotFoundError:\n",
    "                    current_image_path=gt_image_path[:-6] + '.tif'\n",
    "                    current_image = cropper.crop(tifffile.imread(current_image_path))\n",
    "\n",
    "            current_image[(current_image!=3) & (current_image != 4) & (current_image !=5)] = 0\n",
    "            current_image = current_image.astype(np.uint8)\n",
    "            root.create_dataset(name = current_directory.split(\"_\")[-1], data = current_image, shape = current_image.shape, chunks=32)\n",
    "            if \"ariadne\" not in current_directory and \"predictions\" not in current_directory and \"refinements\" not in current_directory:\n",
    "                all_images.append(current_image)\n",
    "            #write out n5\n",
    "        all_images = np.stack(tuple(all_images))\n",
    "        all_images = all_images==3\n",
    "        all_image_variance = np.var(all_images, axis=0).astype(np.float32)\n",
    "        root.create_dataset(name = \"mito_mem_variance\", data = all_image_variance, shape = current_image.shape, chunks=32)\n",
    "        #root.create_dataset(name = current_directory.split(\"_\")[-1], data = current_image, shape = current_image.shape, chunks=32)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 70)\n",
      "0     3450.0\n",
      "1     6670.0\n",
      "2     3840.0\n",
      "3     7800.0\n",
      "4     7068.0\n",
      "       ...  \n",
      "65       NaN\n",
      "66       NaN\n",
      "67       NaN\n",
      "68       NaN\n",
      "69       NaN\n",
      "Name: x, Length: 70, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(\"MaskingInformationAmiraCoordinatesNewColumns.csv\",header=[0,1])\n",
    "print(df.shape)\n",
    "def df_get(df, column, subcolumn=None):\n",
    "    if subcolumn:\n",
    "        return df[column][subcolumn]\n",
    "    else:\n",
    "        # Way to treat it when  contains eg unnamed 0_level_0\n",
    "        return df[column][df[column].keys()[0]]\n",
    "print(df_get(df, \"original coordinates\",\"x\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]]\n"
     ]
    }
   ],
   "source": [
    "a=zarr.open(\"/groups/cosem/cosem/ackermand/annotation_and_analytics/n5s/group1/group1_01.n5\",mode=\"r\")[\"1b\"]\n",
    "print(a[1:3,1:3,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.24607862 1.         0.23882335 0.3075039 ]\n",
      "  [0.54708079 0.06451196 0.74182371 1.        ]\n",
      "  [1.         0.87201322 1.         0.70389306]]\n",
      "\n",
      " [[1.         1.         1.         1.        ]\n",
      "  [1.         0.47092077 1.         1.        ]\n",
      "  [0.34139064 0.010073   0.02635959 1.        ]]]\n",
      "[[[0.44189268 0.98452095 0.34599206 0.41164648]\n",
      "  [0.3059832  0.43125672 0.345327   0.53013013]\n",
      "  [0.80911424 0.28171243 0.85383461 0.029224  ]]\n",
      "\n",
      " [[0.9069194  0.53428262 0.85601761 0.90305499]\n",
      "  [0.58269879 0.05278758 0.59659958 0.70724134]\n",
      "  [0.22252238 0.37224568 0.13555516 0.56271096]]]\n",
      "[[[[0.24607862 1.         0.23882335 0.3075039 ]\n",
      "   [0.54708079 0.06451196 0.74182371 1.        ]\n",
      "   [1.         0.87201322 1.         0.70389306]]\n",
      "\n",
      "  [[1.         1.         1.         1.        ]\n",
      "   [1.         0.47092077 1.         1.        ]\n",
      "   [0.34139064 0.010073   0.02635959 1.        ]]]\n",
      "\n",
      "\n",
      " [[[0.44189268 0.98452095 0.34599206 0.41164648]\n",
      "   [0.3059832  0.43125672 0.345327   0.53013013]\n",
      "   [0.80911424 0.28171243 0.85383461 0.029224  ]]\n",
      "\n",
      "  [[0.9069194  0.53428262 0.85601761 0.90305499]\n",
      "   [0.58269879 0.05278758 0.59659958 0.70724134]\n",
      "   [0.22252238 0.37224568 0.13555516 0.56271096]]]]\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "a=np.random.random((2,3,4))\n",
    "b=np.random.random((2,3,4))\n",
    "a[b>0.5]=1\n",
    "c=np.stack((a,b))\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(np.var(c,axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.3333333333333333"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(np.asarray([0,0,1,1]),ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[2]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=[1,2,3]\n",
    "f[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a=1+5\n",
    "b=a+2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 1.]]\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 2. 2. 2. 1.]\n",
      " [1. 2. 3. 3. 2. 1.]\n",
      " [1. 2. 3. 3. 2. 1.]\n",
      " [1. 2. 2. 2. 2. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "[[ True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True]\n",
      " [False  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True]]\n",
      "[[ 0.         -1.         -1.         -1.         -1.          0.        ]\n",
      " [-1.         -1.          0.          0.          0.          0.        ]\n",
      " [-1.41421356 -1.         -1.          0.         -1.          0.        ]\n",
      " [-1.          0.         -1.          0.          0.          0.        ]\n",
      " [ 0.         -1.         -1.         -1.         -1.          0.        ]\n",
      " [ 0.         -1.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "a=np.random.random((6,6))//0.5\n",
    "b=np.zeros((8,8))\n",
    "b[1:7,1:7] = 1\n",
    "d = distance_transform_edt(b)\n",
    "d=d[1:7,1:7]\n",
    "print(a)\n",
    "print(d)\n",
    "print(np.abs(distance(a))<=d)\n",
    "print(distance(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "701d042f6fef65872dbcbe8b54f16fb36c2a192f2ebce024e995970c0e8f0d0a"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}